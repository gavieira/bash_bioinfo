--conda

# Add Bioconda to software channels

conda config --add channels defaults && conda config --add channels bioconda && conda config --add channels conda-forge


--youtube-dl

# Download playlist (ordered and with autosubs, ignoring errors):

youtube-dl -f best -o "%(autonumber)s-%(title)s.%(ext)s" -i --write-auto-sub <playlist url>

--jupyter-lab (open remotely) - https://amber-md.github.io/pytraj/latest/tutorials/remote_jupyter_notebook

In remote host, open the terminal, change directory to where you have your notebooks and type:

jupyter notebook --no-browser --port=8889
#Leave it open

In local computer, type (port forwarding):

ssh -N -f -L localhost:8888:localhost:8889 username@your_remote_host_name

Now you can access the remote host's jupyter-lab at:

localhost:8888

-- symbolic links (symlinks)

#To create, use:

ln -s {source-filename} {symbolic-filename}

-- docker

#Create container from image:

docker run --name teste conda/miniconda3 /bin/bash

#Run container in interactive shell:

docker start -i teste

#Remove containers:

docker container rm container1 container2

#Remove images:

docker image rm image1 image2

#Run container with $PWD as volume:

docker run -d -v $PWD:/mnt -w /mnt  container_name command_line

#Stop/remove all of Docker containers:

docker stop $(docker ps -a -q)
docker rm $(docker ps -a -q)

or:

docker rm -f $(docker ps -a -q) #Both stops/removes

#Useful link: https://www.digitalocean.com/community/tutorials/how-to-remove-docker-images-containers-and-volumes

##Remove all images:

docker rmi $(docker images -a -q)

##Remove dangling (not associated with container) images, volumes, etc:

docker system prune

##Remove everything:

docker system prune -a

-- mitos

runmitos.py -i <fasta_file> -c <genetic_code> -o <output_dir> -r <reference_dir>

Obs: Reference dir can be found at https://zenodo.org/record/2672835#.XhsxXJnQ_iw

--bash for loop

#When all files of interest are in the same dir, you don't need to use 'ls' or 'find' to get a list of them.

for i in /path/to/dir/*.gb; do echo $i; done    #Will return all files from a given directory with a '.gb' extension

#When files are spread throughout several folders, using the find command may be a good idea, But you will have to change the IFS (Internal Field Separator) to parse its output

IFS=$'\n'; for i in $(find . -name *.fa); do echo "This is the file" $i; done && unset IFS  #Find all files with .fa extension and can perform operations on them

#You can also get the absolute path to directories, go inside them, and remove all files except by those with some specific extension:

for i in $PWD/*/; do cd $i && rm -rf !(*extension); done

-- rm

#Remove everything except certain files

rm !(file1.txt|file2.zip|file3.jpg)

--cut

Mandatory arguments to long options are mandatory for short options too.
  -b, --bytes=LIST        select only these bytes
  -c, --characters=LIST   select only these characters
  -d, --delimiter=DELIM   use DELIM instead of TAB for field delimiter
  -f, --fields=LIST       select only these fields;  also print any line
                            that contains no delimiter character, unless
                            the -s option is specified
  -n                      (ignored)
      --complement        complement the set of selected bytes, characters
                            or fields
  -s, --only-delimited    do not print lines not containing delimiters
      --output-delimiter=STRING  use STRING as the output delimiter
                            the default is to use the input delimiter
  -z, --zero-terminated    line delimiter is NUL, not newline
      --help     display this help and exit
      --version  output version information and exit

#Imprimir apenas alguns campos do arquivo original (cut assume TAB como delimiter padrão):

cut -f1,2,5,6 --complement PFERALIS_ARTEMIS.gff

#Excluir campo (coluna) do arquivo original:

cut -f4 --complement PFERALIS_ARTEMIS.gff

#String slicing with cut:

echo "morango" | cut -c2 #Gets the second character ("o")

echo "morango" | cut -c2-5 #Gets from second to fifth character ("oran")

echo "morango" | cut -c2- #Gets from second to last character ("orango")

echo "morango" | cut -c-5 #Gets from second to fifth character ("moran")

#Getting ids for multiple fasta files with cut (with ">"):

for i in *fasta; do header=$(cut -d '>' -f 1,2 -s $i) && echo $header; done
-d '>' = sets '>' as separator
-f 1,2 = returns both separated fields ('>', sequence_id)
-s = prints only the lines that have the separator character

#Getting ids for multiple fasta files with cut (without ">"):

for i in *fasta; do header=$(cut -d '>' -f 2 -s $i) && echo $header; done

--awk

#Substituir texto em uma unica coluna:

awk -F"\t" '{gsub("gene","CDS",$3); print}' OFS="\t"  PPERBOSCII_ARTEMIS.gff > NEW.gff

Troca a string "gene" por "CDS" na coluna 3, usando tab ("\t") como separador.


#Imprimir linhas em que uma coluna seja >= x:
awk '$4>=2{print}' filename (Imprme linhas nas quais a coluna 4 tenha valor >= a 2)


#pegar uma sequencia de um arquivo multifasta com base no ID:

awk -vRS=">" 'BEGIN{t["ID da sequencia"]=1} {if($1 in t){printf ">%s",$0}}'  sequence.fasta

Cria objeto t, e se esse objeto está na linha, ele o imprime até o próximo separador (>).


#Get system usernames:

awk -F: '{print $1}' /etc/passwd


#Get groups and associated users:

awk -F: '{print $1, "-", $NF}' /etc/group

NF corresponds to "Number of Fields". Thus, this oneliner gets the first and last fields.

--sed

# Gerar arquivos com apenas as linhas de 1 a 125 do arquivo original:

sed -n 1,125p input.file > output.file

#Multiple line ranges:

sed -n '2,4p;6,8p' file.txt

#Substituir pattern sem abrir arquivo:

sed -i -e 's/few/asd/g' hello.txt

s/ substitui 'few' por 'asd' no arquivo hello.txt
/g stands for "global" - substitui todos os 'few' na msma linha

sed "s/'/\"/g"  Input_file -  troca single quote por double quote

--ls

#Listar apenas pastas:
ls -ld */

#listar apenas um arquivo por linha:
ls -1

#Listar continuamente (refresh 3 segundos)
watch -n3 ls -ltrh

watch - repete o comando.


# Parar processo, colocar no background e adicionar nohup:
Ctrl+Z (para o processo)
bg (coloca no background - &)
job (para ver o número do job)
disown -h %[nº_do_job - coloca o nohup
ex: disown -h %1


--tar

#Comprimir:

tar -cjvf files.tar.bz2 stuff => comprime para .tar.bz2 (+ lento, mas mais compactado)


tar -czvf files.tar.gz /usr/local/something => comprime para .tar.gz (+rápido e menos compacto)

tar -cakvf files.tar.bz2 /usr/local => Identifica o programa para compressão a partir da extensão do arquivo (no caso, bz2). Mantém o arquivo original

-c : create - cria um arquivo (não deleta o anterior_
-z: comprime com gzip
-j: comprime bzip2
-a: identifica qual compressão usar baseado na extensão do arquivo
-f: vc especifica o nome do arquivo de saida
-k: mantém arquivo original

tar -cavf files.tar.gz /home/ubuntu --exclude='/home/ubuntu/Downloads' --exclude='/home/ubuntu/.cache' => Comprime tudo exceto (aceita wildcard)


--tail

#Ver arquivos de log em tempo real (20 linhas)

tail -n 20 -f nome_do_arquivo.txt


--uname

#Checar qual versão do Linux (32 ou 64 bits) vc está usando:
uname -a

--paste

#Merge files as different collumns:
paste file1 file2 > 2collumns.txt

--less

#See line numbers:
less -N file.txt

--chsh

#Change SHELL (from /bin/sh to /bin/bash, por exemplo)

sudo chsh -s /bin/bash <username>

(alternativamente, vc pode adicionar a linha "/bin/bash" no fim do arquivo  ~/.profile

--chmod

chmod [ugoa][+-=][rwxXst] filename


#For directories, use -R (ex: grant execute to all):

chmod -R +x dir


--scp

#scp (mandar arquivo pra outra máquina, sem entrar nela)
scp -P 2019  PGRACILIS_FILTERED_DENOVO_K37_out.ace gabriel@ip_remotehost:~
scp -P 2019 -r PGRACILIS_FILTERED_DENOVO_K37 gabriel@ip_remotehost:~ (para diretório)


#scp (pegar arquivo de outra máquina, sem entrar nela)
scp -P 2019 gabriel@ip_remotehost:/path/to/file.txt /some/local/directory

Copy multiple files from the remote host to your current directory on the local host
scp your_username@remotehost.edu:~/\{foo.txt,bar.txt\} .


--trimmomatic

java -jar trimmomatic-0.35.jar PE -threads 12 -phred33 input_forward.fq.gz input_reverse.fq.gz -baseout basename.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36


--grep

# usando grep para identificar padrão no fim da string

ls -R | grep '\.rar$'
$ é o REGEX q indica o fim da string.


Grep apenas para marcar matches no texto:
grep -z filename.txt


--lscpu

#informações sobre cpu (incluindo número de processadores):
lscpu

--lsb-realease

#Checar qual versão de Linux OS está instalada:
lsb_release -a

--miraconvert

miraconvert  -f <input_format> -t <output_format> Arquivo.informat Arquivo.outformat
miraconvert  -f maf -t ace -r C -r f PGRACILIS_AGORAVAI_out.maf PGRACILIS_AGORAVAI_out.ace
miraconvert -f maf -t fasta -r C -r f lniger-REFERENCE_out.maf lniger-ACGT


--SRAtoolkit

Baixar arquivo .sra (baixa para ~/ncbi/public/sra)
path/to/prefetch <accession number>

Converter sra em fastq (substituir split-spot por split-3 ou split-files para R1 e R2):
nohup /bioinfo/sratoolkit.2.8.1-centos_linux64/bin/fastq-dump.2.8.1 --split-spot --clip --read-filter pass --skip-technical --readids --dumpbase SRR1742979.Pgracilis.sra &

-X 10000 - Imprime os primeiros 10000 spots.

--origfmt - O cabeçalho fica no formato Illumina

CHANGE HEADER:

fastq-dump --split-files --defline-seq '@$ac-$sn/$ri' --defline-qual '+' -O ./ ACCESSION




--NOVOPlasty

Chama o script e diz onde está o arquivo de configuração.
nohup perl ~/bioinfo/NOVOPlasty-master/NOVOPlasty2.6.pl -c config.txt > NOVOPlasty.out 2> NOVOPlasty.err &

config.txt :

Insert_size: SRA run selector.
Read Length: só dar um less no fast
SEED: procurar gene mitocondrial da espécie ou gênero (usar filt "genetic compartiments" do genbank)




--MITObim

nohup /bioinfo/MITObim-master/MITObim_1.8.pl -end 40 --clean -sample pgracilis -ref REFERENCE -readpool ../SRR1742979.Pgracilis.fastq -maf PGRACILIS_AGORAVAI_d_results/PGRACILIS_AGORAVAI_out.maf > mitobim.out 2> mitobim.err &

Interleaved fastq (para rodar paired end):
/bioinfo/MITObim-master/misc_scripts/interleave-fastqgz-MITOBIM.py SRR5150667.Taethiops_1.fastq SRR5150667.Taethiops_2.fastq > SRR5150667.Taethiops_interleaved.fastq



--fastqc

nohup fastqc -o fastqc_out/ SRR5112522.Pevitus_2.fastq &


--bowtie2

#Bowtie2-build - cria database para o bowtie2

bowtie2-build 13FORM.fasta 13FORM

#Roda BOWTIE2
nohup bowtie2 -x 13FORM -U SRR1743140.Pgracilis.fastq -S SRR1743140.Pgracilis.sam --no-unal --no-head --very-sensitive-local -p 32 &
nohup bowtie2 -x PVENEFICUS -1 SRR5112539.Pmixtecus_1.fastq -2 SRR5112539.Pmixtecus_2.fastq -S SRR5112539.Pmixtecus.sam --no-unal --no-head --very-sensitive-local -p 8 &

#Obtem a lista de ids das reads mapeadas
cat SRR1743140.Pgracilis.sam | awk '{print $1}' | sort -u > readList.info



--genechecker

python /bioinfo/mitoMaker/geneChecker.py ../Srichteri.gb JWHX01003879.fasta JWHX01003879.gb


--spades

nohup /bioinfo/SPAdes-3.10.0-Linux/bin/spades.py -o PPALIDUS_SPADES_DENOVO_2MILLION -1 SRR1742947.Ppallidus.0bp_pass_1.fastq -2 SRR1742947.Ppallidus.0bp_pass_2.fastq --threads 24 --memory 20 -k 61,73,79,89,47,23 >spades.out >spades.err &

